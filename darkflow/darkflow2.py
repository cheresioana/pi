# -*- coding: utf-8 -*-
"""Darkflow2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1efkq6MXOPOEHLYx9mKSmncOx7nbXlb_t

Mount at spiderwebcluj
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
#choose tensor version & install darkflow
# %cd /content/gdrive/'My Drive'/desene/darkflow/
# %tensorflow_version 1.x
!python3 setup.py build_ext --inplace
!pip install -e .

!apt-get update
!pip3 install numpy
!apt-get install python-opencv -y
!pip install cython

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow
!python setup.py build_ext --inplace

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'
# %mkdir desene
# %ls
# %cd /content/gdrive/'My Drive'/desene
!git clone https://github.com/thtrieu/darkflow

"""Adding my repo from bitbucker with all the data."""

# Commented out IPython magic to ensure Python compatibility.
# %cd  /content/gdrive/'My Drive'/desene
!git clone https://icheres:cheresoaia@bitbucket.org/icheres/desene_proj.git

"""Make sure that you are using the right tensorflow version"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow/
# %tensorflow_version 1.0

"""Check the right labels to be in labesl.txt"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow/
! echo -e "tom\njerry" > labels.txt
# %cat labels.txt

"""Training on the new dataset"""

# Commented out IPython magic to ensure Python compatibility.
# %cd train
# %ls img

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow/

!flow --model cfg/tiny-yolo-voc-2c.cfg --train --dataset "train/img" --annotation "train/xml" --gpu 1.0 --epoch 1000 --load 8500

"""configure flow command"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow/
!pip install -e .

!flow --h

# Commented out IPython magic to ensure Python compatibility.
# %cp /content/gdrive/'My Drive'/desene/desene_proj/my_files/test/test.mp4  /content/gdrive/'My Drive'/desene/darkflow

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow/
!flow --demo full_movie.mp4 --model cfg/tiny-yolo-voc-2c.cfg --load 29500 --gpu 0.8 --saveVideo --threshold 0.3

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow/ckpt
# %ls

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow/

# %ls
#%cp /content/gdrive/'My Drive'/desene/desene_proj/my_files/vid2.mp4 .
!flow --imgdir 'train/img' --model cfg/tiny-yolo-voc-2c.cfg --load 29500 --gpu 0.8

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow
!pip install -e .

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow
!python3 setup.py build_ext --inplace

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/'My Drive'/desene/darkflow
import cv2
from darkflow.net.build import TFNet
import numpy as np
import time
import functools 
from google.colab.patches import cv2_imshow

options = {
    'model' : 'cfg/tiny-yolo-voc-2c.cfg',
    'load' : 29500,
    'threshold': 0.005,
    'gpu': 0.8
}

tfnet = TFNet(options)
colors = [(0, 0, 255), (255, 255, 200)]



mask = np.zeros(imgcv.shape[:2], np.uint8)

bgModel = np.zeros((1, 65), np.float64)
fgModel = np.zeros((1, 65), np.float64)
cv2.grabCut(imgcv, mask, jerry_rect, bgModel, fgModel, 5, cv2.GC_INIT_WITH_RECT)
mask2 = np.where((mask == 2) | (mask==0), 0, 1).astype('uint8')
img2 = imgcv * mask2[:, :, np.newaxis]
cv2_imshow(img2)

mask3 = np.zeros(imgcv.shape[:2], np.uint8)

bgModel = np.zeros((1, 65), np.float64)
fgModel = np.zeros((1, 65), np.float64)
cv2.grabCut(imgcv, mask3, tom_rect, bgModel, fgModel, 5, cv2.GC_INIT_WITH_RECT)
mask3 = np.where((mask3 == 2) | (mask3==0), 0, 1).astype('uint8')
img3 = imgcv * mask3[:, :, np.newaxis]
cv2_imshow(img3)

imgcv = cv2.imread("./test/input/0.jpg")
result = tfnet.return_predict(imgcv)
print(result)
tom = functools.reduce(lambda a,b: a if (a['confidence'] > b['confidence']) else b, [x for x in result if x['label']=='tom']);
jerry = functools.reduce(lambda a,b: a if (a['confidence'] > b['confidence']) else b, [x for x in result if x['label']=='jerry']);
tom_crop = imgcv[tom['topleft']['y'] :tom['bottomright']['y'], tom['topleft']['x'] :tom['bottomright']['x']]
jerry_rect = (jerry['topleft']['x'], jerry['topleft']['y'] ,jerry['bottomright']['x'] - jerry['topleft']['x'] ,jerry['bottomright']['y'] - jerry['topleft']['y'])
tom_rect = (tom['topleft']['x'], tom['topleft']['y'] ,tom['bottomright']['x'] - tom['topleft']['x'] ,tom['bottomright']['y'] - tom['topleft']['y'])
jerry_crop = imgcv[jerry['topleft']['y']  :jerry['bottomright']['y'] , jerry['topleft']['x'] :jerry['bottomright']['x'] ]

from imutils import contours
'''gray = cv2.cvtColor(jerry_crop, cv2.COLOR_BGR2GRAY)
cv2_imshow(gray)
retval, thresh_gray = cv2.threshold(gray, thresh=100, maxval=255, type=cv2.THRESH_BINARY_INV)
cv2_imshow(thresh_gray)

contours, hierarchy = cv2.findContours(thresh_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

max_contour = max(contours, key=lambda a:a.size)
print(max_contour.size)

cv2.drawContours(jerry_crop, max_contour, -1, (0,255,0), 3)
cv2_imshow(jerry_crop)

mask = np.zeros_like(gray) # Create mask where white is what we want, black otherwise
cv2.drawContours(mask, [max_contour], 0, 255, -1) # Draw filled contour in mask
out = np.zeros_like(gray) # Extract out the object and place into output image
out[mask == 255] = gray[mask == 255]

# Show the output image
cv2_imshow(out)
'''
##TOM
'''gray = cv2.cvtColor(tom_crop, cv2.COLOR_BGR2GRAY)
cv2_imshow(gray)
th3 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY,11,2)

th3 = cv2.bitwise_not(th3)
cv2_imshow(th3)

blur = cv2.medianBlur(th3, 3)
cv2_imshow(blur)

kernel = np.ones((2,2),np.uint8)
erosion = cv2.erode(blur,kernel,iterations = 1)
cv2_imshow(erosion)

#kernel = np.ones((2,1),np.uint8)
#erosion = cv2.erode(erosion,kernel,iterations = 1)
#cv2_imshow(erosion)

#dilation = erosion
kernel = np.ones((4,4),np.uint8)
dilation = cv2.dilate(erosion,kernel,iterations = 1)
cv2_imshow(dilation)

contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

max_contour = max(contours, key=lambda a:a.size)
print(max_contour.size)

cv2.drawContours(tom_crop, [max_contour], 0, (0,255,0), 3)
cv2_imshow(tom_crop)

mask = np.zeros_like(gray) # Create mask where white is what we want, black otherwise
cv2.drawContours(mask, [max_contour], 0, 255, -1) # Draw filled contour in mask
out = np.zeros_like(gray) # Extract out the object and place into output image
out[mask == 255] = gray[mask == 255]

cv2_imshow(out)'''

imgcv = cv2.imread("./test/input/154.jpg")
result = tfnet.return_predict(imgcv)

tom_array = [x for x in result if x['label']=='tom']
jerry_array = [x for x in result if x['label']=='jerry']

if len(tom_array) > 0:
  tom = functools.reduce(lambda a,b: a if (a['confidence'] > b['confidence']) else b, tom_array);
  tom_crop = imgcv[tom['topleft']['y'] :tom['bottomright']['y'], tom['topleft']['x'] :tom['bottomright']['x']]
  tom_rect = (tom['topleft']['x'], tom['topleft']['y'] ,tom['bottomright']['x'] - tom['topleft']['x'] ,tom['bottomright']['y'] - tom['topleft']['y'])

if len(jerry_array) > 0:
  jerry = functools.reduce(lambda a,b: a if (a['confidence'] > b['confidence']) else b, jerry_array);
  jerry_rect = (jerry['topleft']['x'], jerry['topleft']['y'] ,jerry['bottomright']['x'] - jerry['topleft']['x'] ,jerry['bottomright']['y'] - jerry['topleft']['y'])
  jerry_crop = imgcv[jerry['topleft']['y']  :jerry['bottomright']['y'] , jerry['topleft']['x'] :jerry['bottomright']['x'] ]

  gray = cv2.cvtColor(jerry_crop, cv2.COLOR_BGR2GRAY)
  cv2_imshow(gray)
  print(gray.shape)
  th3 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
              cv2.THRESH_BINARY,11,2)

  th3 = cv2.bitwise_not(th3)
  cv2_imshow(th3)

  blur = cv2.medianBlur(th3, 3)
  cv2_imshow(blur)

  kernel = np.ones((2,2),np.uint8)
  erosion = cv2.erode(blur,kernel,iterations = 1)
  cv2_imshow(erosion)

  #kernel = np.ones((2,1),np.uint8)
  #erosion = cv2.erode(erosion,kernel,iterations = 1)
  #cv2_imshow(erosion)

  #dilation = erosion
  kernel = np.ones((4,4),np.uint8)
  if (gray.size < 32400):
    kernel = np.ones((5,5),np.uint8)

  dilation = cv2.dilate(erosion,kernel,iterations = 1)
  cv2_imshow(dilation)


  contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

  max_contour = max(contours, key=lambda a:a.size)
  
  cv2.drawContours(jerry_crop, [max_contour], 0, (50,50,50), 2)
  cv2_imshow(jerry_crop)
  mask = np.zeros_like(gray) 
  cv2.drawContours(mask, [max_contour], 0, 255, -1)
  
  out = np.zeros_like(jerry_crop)
  
  out[mask == 255] = jerry_crop[mask == 255]
  cv2_imshow(out)
 
  rgba = cv2.cvtColor(out, cv2.COLOR_RGB2RGBA)
  #print(rgba)
  rgba[:,:, 3] = 0
  rgba[mask==255, 3] = 255
  cv2_imshow(rgba)
  cv2.imwrite("./out/1color.png", rgba)
  '''rgba = cv2.cvtColor(out, cv2.COLOR_RGB2RGBA)
  rgba[:, :, 3] = 0
  #out = np.expand_dims(out, axis=0) 
  print("rgba zero")
  print(rgba)
  print("out")
  print(out)
  
  rgba[mask == 255, 3] = 1
  print(np.count_nonzero(rgba))
  print("non 0 rgba")
  print(rgba)
  rgba[mask == 255, :3] = jerry_crop[mask == 255]
  cv2_imshow(rgba)
  cv2.imwrite("./out/1color.png", rgba)'''
  
  kernel = np.ones((3,3),np.uint8)
  if (gray.size < 32400):
    kernel = np.ones((4,4),np.uint8)
  
  sketchy = cv2.erode(dilation,kernel,iterations = 1)
  sketchy = cv2.bitwise_not(sketchy)
  mask = np.zeros_like(gray) 
  cv2.drawContours(mask, [max_contour], 0, 255, -1)
  out = np.zeros_like(sketchy)
  out[mask == 255] = sketchy[mask == 255]
  cv2.imwrite("./out/1sketchy.png", out)
  cv2_imshow(out)

def process_image(img, number):
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  th3 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
              cv2.THRESH_BINARY,11,2)
  th3 = cv2.bitwise_not(th3)
  blur = cv2.medianBlur(th3, 3)
  kernel = np.ones((2,2),np.uint8)
  erosion = cv2.erode(blur,kernel,iterations = 1)
  kernel = np.ones((4,4),np.uint8)

  if (gray.size < 32400):
    kernel = np.ones((5,5),np.uint8)
  
  dilation = cv2.dilate(erosion,kernel,iterations = 1)
  contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
  max_contour = max(contours, key=lambda a:a.size)
  cv2.drawContours(img, [max_contour], 0, (50,50,50), 2)
  mask = np.zeros_like(gray) 
  cv2.drawContours(mask, [max_contour], 0, 255, -1)
  
  out = np.zeros_like(img)
  out[:, :] = (255, 255, 255)
  out[mask == 255] = img[mask == 255]
  rgba_color = cv2.cvtColor(out, cv2.COLOR_RGB2RGBA)
  rgba_color[:,:, 3] = 0
  rgba_color[mask==255, 3] = 255
  rgb_color = out
  #cv2.imwrite("./out/" + str(number) + "color.png", rgba)
  
  
  kernel = np.ones((3,3),np.uint8)
  if (gray.size < 32400):
    kernel = np.ones((4,4),np.uint8)
  
  sketchy = cv2.erode(dilation,kernel,iterations = 1)
  sketchy = cv2.bitwise_not(sketchy)
  mask = np.zeros_like(gray) 
  cv2.drawContours(mask, [max_contour], 0, 255, -1)
  out = np.zeros_like(sketchy)
  out[mask == 255] = sketchy[mask == 255]
  rgba_sketch = cv2.cvtColor(out, cv2.COLOR_RGB2RGBA)
  rgba_sketch[:,:, 3] = 0
  rgba_sketch[mask==255, 3] = 255
  #cv2.imwrite("./out/" + str(number) + "sketchy.png", rgba)
  return (rgba_color, rgb_color, rgba_sketch)

def check_result(color, rgb_color, sketch, label, number, frame):
  #result = tfnet.return_predict(rgb_color)
  #array = [x for x in result if x['label']==label]
  #if (len(array) > 0):
  cv2.imwrite("./out/" + str(number) + label + "color.png", color)
  #cv2.imwrite("./out/" + str(number) + label + "rgbcolor.png", rgb_color)
  cv2.imwrite("./out/" + str(number) + label + "sketch.png", sketch)
  #cv2.imwrite("./out/" + str(number) + label + "frame.png", frame)

import cv2
cap = cv2.VideoCapture("/content/gdrive/My Drive/desene/desene_proj/my_files/vid3.mp4")
count = 0
f = open("./data.txt", "w")
f.write("x_tom,y_tom,photo_tom,x_jerry,y_jerry,photo_jerry,pred_x_tom,pred_y_tom,pred_photo_tom,pred_x_jerry,pred_y_jerry,pred_photo_jerry\n")
s1 = None
s2 = None
while cap.isOpened() and count < 500:
    ret,frame = cap.read()
    detect_anything = 0;
    if count == 0:
      print(frame.shape)
    if ret :
      result = tfnet.return_predict(frame)
      tom_array = [x for x in result if x['label']=='tom']
      jerry_array = [x for x in result if x['label']=='jerry']
      tom_photo_number = -1;
      jerry_photo_number = -1;
      tom_corner = (-1, -1);
      jerry_corner = (-1, -1);
      if len(tom_array) > 0:
        detect_anything = 1;
        tom = functools.reduce(lambda a,b: a if (a['confidence'] > b['confidence']) else b, tom_array);
        tom_crop = frame[tom['topleft']['y'] :tom['bottomright']['y'], tom['topleft']['x'] :tom['bottomright']['x']]
        tom_corner = (tom['topleft']['x'], tom['topleft']['y'])
        rgba_color, rgb_color, rgba_sketch = process_image(tom_crop, count)
        check_result(rgba_color, rgb_color, rgba_sketch, "tom", count, frame)
        tom_photo_number = count

      if len(jerry_array) > 0:
        detect_anything = 1;
        jerry = functools.reduce(lambda a,b: a if (a['confidence'] > b['confidence']) else b, jerry_array);
        jerry_crop = frame[jerry['topleft']['y']  :jerry['bottomright']['y'] , jerry['topleft']['x'] :jerry['bottomright']['x'] ]
        jerry_corner = (jerry['topleft']['x'], jerry['topleft']['y'])
        rgba_color, rgb_color, rgba_sketch = process_image(jerry_crop, count)
        check_result(rgba_color, rgb_color, rgba_sketch, "jerry", count, frame)
        jerry_photo_number = count
      
      if detect_anything == 0:
        s1 = None
      elif s1 == None:
        s1 = str(tom_corner[0]) + "," + str(tom_corner[1]) + "," + str(tom_photo_number) + "," + str(jerry_corner[0]) + "," + str(jerry_corner[1]) + "," + str(jerry_photo_number);
      else:
        s2 = str(tom_corner[0]) + "," + str(tom_corner[1]) + "," + str(tom_photo_number) + "," + str(jerry_corner[0]) + "," + str(jerry_corner[1]) + "," + str(jerry_photo_number);
        f.write(s1 + "," + s2 + "\n");
        s1 = s2;
      count = count + 1

      
f.close()
print(count)
cap.release()
cv2.destroyAllWindows()

import tensorflow as tf

import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd

df = pd.read_csv("./data.txt")
df.head()

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df.head()

y = df[['pred_x_tom', 'pred_y_tom', 'pred_photo_tom' ,'pred_x_jerry' ,'pred_y_jerry','pred_photo_jerry']]
x = df[['x_tom', 'y_tom', 'photo_tom' ,'x_jerry' ,'y_jerry','photo_jerry']]
y_scaler = MinMaxScaler()
x_scaler = MinMaxScaler()
x = x_scaler.fit_transform(x)
y = y_scaler.fit_transform(y)
print(x)
print(y)

data_len = len(x)
train_len = (int)(1 * data_len)
test_len = data_len - train_len
X_train = x[:train_len]
Y_train = y[:train_len]
X_test = x[train_len + 1:]
Y_test = y[train_len + 1:]

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
model = Sequential()
model.add(LSTM(1, input_shape=(1, 6)))
model.add(Dense(6))
model.compile(loss='mean_squared_error', optimizer='adam')
print(X_train.shape)
X_train_final = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))
print(X_train_final.shape)
model.fit(X_train_final, Y_train, epochs=150, batch_size=1, verbose=2)

trainPredict = model.predict(X_train_final)


trainPredict = np.reshape(trainPredict, (X_train.shape[0], X_train.shape[1]))

trainPredict = y_scaler.inverse_transform(trainPredict)

print(trainPredict)
np.savetxt("model_results.txt", trainPredict)

from random import random, randint
all_data = None
iter = 0;
while iter < 20:
  r = randint(0, 450)
  first = X_train_final[r]
  print(first)
  first = np.reshape(first, (1, 1, 6))
  predict1 = model.predict(first)
  if all_data is None:
    all_data = np.array(first[0])  
  else:
    all_data = np.vstack((all_data, first[0]))
  i = 0;
  while i < 20:
    predict1 = np.reshape(predict1, (1, 1, 6))
    predict2 = model.predict(predict1)
    all_data = np.vstack((all_data, np.array(predict2[0])))
    predict1 = predict2
    i = i + 1;
  iter = iter + 1

all_data = np.reshape(all_data, (len(all_data), 6))

all_data = y_scaler.inverse_transform(all_data)
print(len(all_data))
np.savetxt("model_predict3.txt", all_data)

matrix = np.loadtxt("model_predict3.txt", usecols=range(6))
print(matrix)
print(len(matrix))

# Commented out IPython magic to ensure Python compatibility.
import cv2
# %ls

from google.colab.patches import cv2_imshow

frame_x = 480
frame_y = 640
count = 0
out_folder = "./results5/"
img_type = "sketch"
for item in matrix:
  blank_image = np.zeros((480,640,4), np.uint8)
  blank_image[:, :, :] = (255, 255, 255, 0)
  
  tom_nr = (int)(item[2])
  tom_x = (int)(item[0])
  tom_y = (int)(item[1])
  jerry_nr = (int)(item[5])
  jerry_x = (int)(item[3])
  jerry_y = (int)(item[4])
  img_jerry = None
  img_tom = None
  if tom_nr != -1:
    img_tom = cv2.imread("./out/"+ str(tom_nr) + "tom" + img_type + ".png", cv2.IMREAD_UNCHANGED)
  if jerry_nr != -1:  
    img_jerry = cv2.imread("./out/"+ str(jerry_nr) + "jerry"+ img_type + ".png", cv2.IMREAD_UNCHANGED)
  #cv2_imshow(blank_image[:, :, :3])
  if (img_tom is not None):
    try:
      tom_x_end = tom_x + img_tom.shape[0]
      tom_y_end = tom_y + img_tom.shape[1]
      
    
      if (tom_y_end > frame_y):
        tom_y = tom_y - (tom_y_end - frame_y)
        tom_y_end = tom_y + img_tom.shape[1]
      if (tom_x_end > frame_x):
        tom_x = tom_x - (tom_x_end - frame_x)
        tom_x_end = tom_x + img_tom.shape[0]
      r = 0
      for i in range(tom_x, tom_x_end):
        c = 0
        for j in range(tom_y, tom_y_end):
          if img_tom[r, c, 3] == 255:
            blank_image[ i, j] = img_tom[r, c]
          c = c + 1;
        r = r + 1
      #cv2_imshow(blank_image) 
      #cv2_imshow(blank_image)
    except:
      print("aia e")
  if (img_jerry is not None):
    try:    
      jerry_x_end = jerry_x + img_jerry.shape[0]
      jerry_y_end = jerry_y + img_jerry.shape[1]
      if (jerry_y_end > frame_y):
        jerry_y = jerry_y - (jerry_y_end - frame_y)
        jerry_y_end = jerry_y + img_jerry.shape[1]
      if (jerry_x_end > frame_x):
        jerry_x = jerry_x - (jerry_x_end - frame_x)
        jerry_x_end = jerry_x + img_jerry.shape[0]
      r = 0
      for i in range(jerry_x, jerry_x_end):
        c = 0
        for j in range(jerry_y, jerry_y_end):
          if img_jerry[r, c, 3] == 255:
            blank_image[ i, j] = img_jerry[r, c]
          c = c + 1;
        r = r + 1
      #cv2_imshow(blank_image) 
    except:
      print("aia e")
  if (img_jerry is not None or img_tom is not None):
    #cv2_imshow(blank_image)
    cv2.imwrite(out_folder + str(count) + ".jpg", blank_image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])
  count = count + 1
  if count % 10 == 0:
    print(count)
print("gata")